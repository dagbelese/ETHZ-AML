{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73216fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import biosppy.signals.ecg as ecg\n",
    "import neurokit2 as nk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01622777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "X = pd.read_csv('X_train.csv', index_col='id')\n",
    "y = pd.read_csv('y_train.csv', index_col='id')\n",
    "X_test_sub = pd.read_csv('X_test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b366749",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sub = pd.read_csv('X_test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6768b13",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119761e5",
   "metadata": {},
   "source": [
    "### time-domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73aa94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time domain analysis\n",
    "def interval_time(i,df,signal):\n",
    "    try:\n",
    "        peaks, info = nk.ecg_peaks(signal, sampling_rate=300)\n",
    "        df_signal = nk.hrv_time(peaks, sampling_rate=300, show=False)\n",
    "        df_new = pd.concat([df,df_signal])\n",
    "\n",
    "    except:\n",
    "        a = np.empty((1,24,))\n",
    "        a[:] = np.nan \n",
    "        a[0]\n",
    "        df_signal = pd.DataFrame(a[0]).T\n",
    "        df_new = pd.concat([df,df_signal])\n",
    "        print(i, \"mama mia, not good\")\n",
    "\n",
    "    return(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d95427f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501a885ce4d84cca8a055142e0eb2efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1870 mama mia, not good\n"
     ]
    }
   ],
   "source": [
    "#time domain - X_train\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    df = interval_time(i,df, X.loc[i].dropna().to_numpy(dtype='float32'))\n",
    "X_time = df\n",
    "X_time.to_csv('X_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efaed08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f067c84437d9441498e545fcafb0a844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 mama mia, not good\n",
      "700 mama mia, not good\n"
     ]
    }
   ],
   "source": [
    "#time domain - X_test\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in tqdm(range(X_test_sub.shape[0])):\n",
    "    df = interval_time(i,df, X_test_sub.loc[i].dropna().to_numpy(dtype='float32'))\n",
    "X_time_test = df\n",
    "X_time_test.to_csv('X_time_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a8f8a",
   "metadata": {},
   "source": [
    "### frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba16acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency domain analysis\n",
    "def interval_frequency(i,df,signal):\n",
    "    try:\n",
    "        peaks, info = nk.ecg_peaks(signal, sampling_rate=300)\n",
    "        df_signal = nk.hrv_frequency(peaks, sampling_rate=300, show=False, normalize=True)\n",
    "        df_new = pd.concat([df,df_signal])\n",
    "\n",
    "    except:\n",
    "        a = np.empty((1,9,))\n",
    "        a[:] = np.nan \n",
    "        a[0]\n",
    "        df_signal = pd.DataFrame(a[0]).T\n",
    "        df_new = pd.concat([df,df_signal])\n",
    "        print(i, \"mama mia, not good\")\n",
    "\n",
    "    return(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b16c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c94f180e104d18aca05bd6a0ef52fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3145 mama mia, not good\n",
      "4388 mama mia, not good\n"
     ]
    }
   ],
   "source": [
    "#frequency domain - X_train\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    df = interval_frequency(i,df, X.loc[i].dropna().to_numpy(dtype='float32'))\n",
    "X_frequ = df\n",
    "X_frequ.to_csv('X_frequ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16605472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f9ea1d995f4ace9108ccf19d614a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 mama mia, not good\n",
      "700 mama mia, not good\n"
     ]
    }
   ],
   "source": [
    "#frequency domain - X_test\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in tqdm(range(X_test_sub.shape[0])):\n",
    "    df = interval_frequency(i,df, X_test_sub.loc[i].dropna().to_numpy(dtype='float32'))\n",
    "X_frequ_test = df\n",
    "X_frequ_test.to_csv('X_frequ_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c046e8f",
   "metadata": {},
   "source": [
    "### nonlinear analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86960a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nonlinear analysis\n",
    "def interval_nonlinear(i,df,signal):\n",
    "    try:\n",
    "        peaks, info = nk.ecg_peaks(signal, sampling_rate=300)\n",
    "        df_signal = nk.hrv_nonlinear(peaks, sampling_rate=300, show=False)\n",
    "        df_new = pd.concat([df,df_signal])\n",
    "\n",
    "    except:\n",
    "        a = np.empty((1,56,))\n",
    "        a[:] = np.nan \n",
    "        a[0]\n",
    "        df_signal = pd.DataFrame(a[0]).T\n",
    "        df_new = pd.concat([df,df_signal])\n",
    "        print(i, \"mama mia, not good\")\n",
    "\n",
    "    return(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f605f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0945f2929b643f0b8b8a5505f97485d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 mama mia, not good\n",
      "16 mama mia, not good\n",
      "19 mama mia, not good\n",
      "29 mama mia, not good\n",
      "47 mama mia, not good\n",
      "55 mama mia, not good\n",
      "69 mama mia, not good\n",
      "85 mama mia, not good\n",
      "96 mama mia, not good\n",
      "102 mama mia, not good\n",
      "103 mama mia, not good\n",
      "108 mama mia, not good\n",
      "140 mama mia, not good\n",
      "155 mama mia, not good\n",
      "165 mama mia, not good\n",
      "186 mama mia, not good\n",
      "199 mama mia, not good\n",
      "220 mama mia, not good\n",
      "261 mama mia, not good\n",
      "264 mama mia, not good\n",
      "269 mama mia, not good\n",
      "273 mama mia, not good\n",
      "299 mama mia, not good\n",
      "337 mama mia, not good\n",
      "338 mama mia, not good\n",
      "354 mama mia, not good\n",
      "356 mama mia, not good\n",
      "396 mama mia, not good\n",
      "398 mama mia, not good\n",
      "411 mama mia, not good\n",
      "421 mama mia, not good\n",
      "434 mama mia, not good\n",
      "458 mama mia, not good\n",
      "471 mama mia, not good\n",
      "488 mama mia, not good\n",
      "493 mama mia, not good\n",
      "516 mama mia, not good\n",
      "527 mama mia, not good\n",
      "538 mama mia, not good\n",
      "559 mama mia, not good\n",
      "589 mama mia, not good\n",
      "603 mama mia, not good\n",
      "609 mama mia, not good\n",
      "617 mama mia, not good\n",
      "620 mama mia, not good\n",
      "629 mama mia, not good\n",
      "655 mama mia, not good\n",
      "658 mama mia, not good\n",
      "685 mama mia, not good\n",
      "687 mama mia, not good\n",
      "690 mama mia, not good\n",
      "692 mama mia, not good\n",
      "698 mama mia, not good\n",
      "737 mama mia, not good\n",
      "753 mama mia, not good\n",
      "763 mama mia, not good\n",
      "781 mama mia, not good\n",
      "804 mama mia, not good\n",
      "808 mama mia, not good\n",
      "809 mama mia, not good\n",
      "815 mama mia, not good\n",
      "846 mama mia, not good\n",
      "847 mama mia, not good\n",
      "848 mama mia, not good\n",
      "877 mama mia, not good\n",
      "885 mama mia, not good\n",
      "887 mama mia, not good\n",
      "892 mama mia, not good\n",
      "901 mama mia, not good\n",
      "905 mama mia, not good\n",
      "917 mama mia, not good\n",
      "919 mama mia, not good\n",
      "968 mama mia, not good\n",
      "981 mama mia, not good\n",
      "1004 mama mia, not good\n",
      "1011 mama mia, not good\n",
      "1022 mama mia, not good\n",
      "1024 mama mia, not good\n",
      "1027 mama mia, not good\n",
      "1028 mama mia, not good\n",
      "1043 mama mia, not good\n",
      "1044 mama mia, not good\n",
      "1046 mama mia, not good\n",
      "1059 mama mia, not good\n",
      "1075 mama mia, not good\n",
      "1107 mama mia, not good\n",
      "1115 mama mia, not good\n",
      "1127 mama mia, not good\n",
      "1134 mama mia, not good\n",
      "1143 mama mia, not good\n",
      "1174 mama mia, not good\n",
      "1177 mama mia, not good\n",
      "1188 mama mia, not good\n",
      "1213 mama mia, not good\n",
      "1228 mama mia, not good\n",
      "1240 mama mia, not good\n",
      "1246 mama mia, not good\n",
      "1258 mama mia, not good\n",
      "1277 mama mia, not good\n",
      "1304 mama mia, not good\n",
      "1305 mama mia, not good\n",
      "1306 mama mia, not good\n",
      "1324 mama mia, not good\n",
      "1337 mama mia, not good\n",
      "1347 mama mia, not good\n",
      "1349 mama mia, not good\n",
      "1350 mama mia, not good\n",
      "1359 mama mia, not good\n",
      "1383 mama mia, not good\n",
      "1391 mama mia, not good\n",
      "1409 mama mia, not good\n",
      "1427 mama mia, not good\n",
      "1455 mama mia, not good\n",
      "1462 mama mia, not good\n",
      "1472 mama mia, not good\n",
      "1493 mama mia, not good\n",
      "1501 mama mia, not good\n",
      "1507 mama mia, not good\n",
      "1514 mama mia, not good\n",
      "1528 mama mia, not good\n",
      "1535 mama mia, not good\n",
      "1560 mama mia, not good\n",
      "1564 mama mia, not good\n",
      "1575 mama mia, not good\n",
      "1579 mama mia, not good\n",
      "1609 mama mia, not good\n",
      "1619 mama mia, not good\n",
      "1626 mama mia, not good\n",
      "1628 mama mia, not good\n",
      "1640 mama mia, not good\n",
      "1681 mama mia, not good\n",
      "1682 mama mia, not good\n",
      "1697 mama mia, not good\n",
      "1700 mama mia, not good\n",
      "1740 mama mia, not good\n",
      "1743 mama mia, not good\n",
      "1763 mama mia, not good\n",
      "1764 mama mia, not good\n",
      "1772 mama mia, not good\n",
      "1820 mama mia, not good\n",
      "1823 mama mia, not good\n",
      "1836 mama mia, not good\n",
      "1847 mama mia, not good\n",
      "1864 mama mia, not good\n",
      "1870 mama mia, not good\n",
      "1915 mama mia, not good\n",
      "1917 mama mia, not good\n",
      "1918 mama mia, not good\n",
      "1928 mama mia, not good\n",
      "1941 mama mia, not good\n",
      "1990 mama mia, not good\n",
      "1999 mama mia, not good\n",
      "2013 mama mia, not good\n",
      "2016 mama mia, not good\n",
      "2032 mama mia, not good\n",
      "2041 mama mia, not good\n",
      "2063 mama mia, not good\n",
      "2107 mama mia, not good\n",
      "2120 mama mia, not good\n",
      "2121 mama mia, not good\n",
      "2131 mama mia, not good\n",
      "2132 mama mia, not good\n",
      "2134 mama mia, not good\n",
      "2165 mama mia, not good\n",
      "2171 mama mia, not good\n",
      "2175 mama mia, not good\n",
      "2186 mama mia, not good\n",
      "2195 mama mia, not good\n",
      "2206 mama mia, not good\n",
      "2214 mama mia, not good\n",
      "2220 mama mia, not good\n",
      "2224 mama mia, not good\n",
      "2226 mama mia, not good\n",
      "2241 mama mia, not good\n",
      "2265 mama mia, not good\n",
      "2296 mama mia, not good\n",
      "2313 mama mia, not good\n",
      "2323 mama mia, not good\n",
      "2326 mama mia, not good\n",
      "2329 mama mia, not good\n",
      "2335 mama mia, not good\n",
      "2336 mama mia, not good\n",
      "2340 mama mia, not good\n",
      "2349 mama mia, not good\n",
      "2354 mama mia, not good\n",
      "2358 mama mia, not good\n",
      "2377 mama mia, not good\n",
      "2384 mama mia, not good\n",
      "2398 mama mia, not good\n",
      "2422 mama mia, not good\n",
      "2424 mama mia, not good\n",
      "2433 mama mia, not good\n",
      "2441 mama mia, not good\n",
      "2444 mama mia, not good\n",
      "2453 mama mia, not good\n",
      "2483 mama mia, not good\n",
      "2502 mama mia, not good\n",
      "2539 mama mia, not good\n",
      "2544 mama mia, not good\n",
      "2546 mama mia, not good\n",
      "2612 mama mia, not good\n",
      "2626 mama mia, not good\n",
      "2627 mama mia, not good\n",
      "2650 mama mia, not good\n",
      "2659 mama mia, not good\n",
      "2674 mama mia, not good\n",
      "2675 mama mia, not good\n",
      "2692 mama mia, not good\n",
      "2700 mama mia, not good\n",
      "2717 mama mia, not good\n",
      "2736 mama mia, not good\n",
      "2749 mama mia, not good\n",
      "2796 mama mia, not good\n",
      "2806 mama mia, not good\n",
      "2809 mama mia, not good\n",
      "2812 mama mia, not good\n",
      "2834 mama mia, not good\n",
      "2839 mama mia, not good\n",
      "2853 mama mia, not good\n",
      "2870 mama mia, not good\n",
      "2873 mama mia, not good\n",
      "2895 mama mia, not good\n",
      "2906 mama mia, not good\n",
      "2912 mama mia, not good\n",
      "2921 mama mia, not good\n",
      "2927 mama mia, not good\n",
      "2928 mama mia, not good\n",
      "2931 mama mia, not good\n",
      "2952 mama mia, not good\n",
      "2953 mama mia, not good\n",
      "2963 mama mia, not good\n",
      "2984 mama mia, not good\n",
      "2997 mama mia, not good\n",
      "3014 mama mia, not good\n",
      "3039 mama mia, not good\n",
      "3053 mama mia, not good\n",
      "3075 mama mia, not good\n",
      "3105 mama mia, not good\n",
      "3120 mama mia, not good\n",
      "3145 mama mia, not good\n",
      "3149 mama mia, not good\n",
      "3159 mama mia, not good\n",
      "3204 mama mia, not good\n",
      "3229 mama mia, not good\n",
      "3238 mama mia, not good\n",
      "3243 mama mia, not good\n",
      "3251 mama mia, not good\n",
      "3267 mama mia, not good\n",
      "3268 mama mia, not good\n",
      "3272 mama mia, not good\n",
      "3280 mama mia, not good\n",
      "3284 mama mia, not good\n",
      "3285 mama mia, not good\n",
      "3288 mama mia, not good\n",
      "3290 mama mia, not good\n",
      "3315 mama mia, not good\n",
      "3332 mama mia, not good\n",
      "3339 mama mia, not good\n",
      "3350 mama mia, not good\n",
      "3355 mama mia, not good\n",
      "3362 mama mia, not good\n",
      "3369 mama mia, not good\n",
      "3377 mama mia, not good\n",
      "3424 mama mia, not good\n",
      "3427 mama mia, not good\n",
      "3444 mama mia, not good\n",
      "3470 mama mia, not good\n",
      "3484 mama mia, not good\n",
      "3497 mama mia, not good\n",
      "3501 mama mia, not good\n",
      "3529 mama mia, not good\n",
      "3538 mama mia, not good\n",
      "3544 mama mia, not good\n",
      "3567 mama mia, not good\n",
      "3579 mama mia, not good\n",
      "3582 mama mia, not good\n",
      "3587 mama mia, not good\n",
      "3598 mama mia, not good\n",
      "3610 mama mia, not good\n",
      "3623 mama mia, not good\n",
      "3626 mama mia, not good\n",
      "3630 mama mia, not good\n",
      "3636 mama mia, not good\n",
      "3641 mama mia, not good\n",
      "3691 mama mia, not good\n",
      "3718 mama mia, not good\n",
      "3720 mama mia, not good\n",
      "3727 mama mia, not good\n",
      "3751 mama mia, not good\n",
      "3754 mama mia, not good\n",
      "3759 mama mia, not good\n",
      "3760 mama mia, not good\n",
      "3774 mama mia, not good\n",
      "3785 mama mia, not good\n",
      "3824 mama mia, not good\n",
      "3826 mama mia, not good\n",
      "3836 mama mia, not good\n",
      "3842 mama mia, not good\n",
      "3843 mama mia, not good\n",
      "3846 mama mia, not good\n",
      "3849 mama mia, not good\n",
      "3871 mama mia, not good\n",
      "3883 mama mia, not good\n",
      "3885 mama mia, not good\n",
      "3887 mama mia, not good\n",
      "3906 mama mia, not good\n",
      "3907 mama mia, not good\n",
      "3917 mama mia, not good\n",
      "3932 mama mia, not good\n",
      "3938 mama mia, not good\n",
      "3944 mama mia, not good\n",
      "3962 mama mia, not good\n",
      "3963 mama mia, not good\n",
      "3988 mama mia, not good\n",
      "3995 mama mia, not good\n",
      "4010 mama mia, not good\n",
      "4021 mama mia, not good\n",
      "4025 mama mia, not good\n",
      "4034 mama mia, not good\n",
      "4052 mama mia, not good\n",
      "4055 mama mia, not good\n",
      "4066 mama mia, not good\n",
      "4084 mama mia, not good\n",
      "4092 mama mia, not good\n",
      "4096 mama mia, not good\n",
      "4131 mama mia, not good\n",
      "4142 mama mia, not good\n",
      "4143 mama mia, not good\n",
      "4148 mama mia, not good\n",
      "4179 mama mia, not good\n",
      "4182 mama mia, not good\n",
      "4184 mama mia, not good\n",
      "4207 mama mia, not good\n",
      "4232 mama mia, not good\n",
      "4272 mama mia, not good\n",
      "4285 mama mia, not good\n",
      "4299 mama mia, not good\n",
      "4301 mama mia, not good\n",
      "4336 mama mia, not good\n",
      "4340 mama mia, not good\n",
      "4341 mama mia, not good\n",
      "4342 mama mia, not good\n",
      "4344 mama mia, not good\n",
      "4385 mama mia, not good\n",
      "4387 mama mia, not good\n",
      "4388 mama mia, not good\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4398 mama mia, not good\n",
      "4403 mama mia, not good\n",
      "4415 mama mia, not good\n",
      "4427 mama mia, not good\n",
      "4428 mama mia, not good\n",
      "4442 mama mia, not good\n",
      "4461 mama mia, not good\n",
      "4470 mama mia, not good\n",
      "4492 mama mia, not good\n",
      "4496 mama mia, not good\n",
      "4520 mama mia, not good\n",
      "4581 mama mia, not good\n",
      "4610 mama mia, not good\n",
      "4612 mama mia, not good\n",
      "4613 mama mia, not good\n",
      "4614 mama mia, not good\n",
      "4638 mama mia, not good\n",
      "4669 mama mia, not good\n",
      "4676 mama mia, not good\n",
      "4701 mama mia, not good\n",
      "4704 mama mia, not good\n",
      "4736 mama mia, not good\n",
      "4747 mama mia, not good\n",
      "4770 mama mia, not good\n",
      "4793 mama mia, not good\n",
      "4803 mama mia, not good\n",
      "4826 mama mia, not good\n",
      "4862 mama mia, not good\n",
      "4863 mama mia, not good\n",
      "4870 mama mia, not good\n",
      "4871 mama mia, not good\n",
      "4874 mama mia, not good\n",
      "4890 mama mia, not good\n",
      "4907 mama mia, not good\n",
      "4919 mama mia, not good\n",
      "4921 mama mia, not good\n",
      "4928 mama mia, not good\n",
      "4959 mama mia, not good\n",
      "4969 mama mia, not good\n",
      "4984 mama mia, not good\n",
      "4985 mama mia, not good\n",
      "4992 mama mia, not good\n",
      "4995 mama mia, not good\n",
      "5006 mama mia, not good\n",
      "5013 mama mia, not good\n",
      "5023 mama mia, not good\n",
      "5032 mama mia, not good\n",
      "5088 mama mia, not good\n",
      "5092 mama mia, not good\n"
     ]
    }
   ],
   "source": [
    "#nonlinear - X_train\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    df = interval_nonlinear(i,df, X.loc[i].dropna().to_numpy(dtype='float32'))\n",
    "X_nl = df\n",
    "X_nl.to_csv('X_nonlinear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252372b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c586d2affe8b4b25ab0612408f72a92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 mama mia, not good\n",
      "17 mama mia, not good\n",
      "25 mama mia, not good\n",
      "83 mama mia, not good\n",
      "88 mama mia, not good\n",
      "91 mama mia, not good\n",
      "96 mama mia, not good\n",
      "98 mama mia, not good\n",
      "105 mama mia, not good\n",
      "111 mama mia, not good\n",
      "149 mama mia, not good\n",
      "156 mama mia, not good\n",
      "161 mama mia, not good\n",
      "215 mama mia, not good\n",
      "242 mama mia, not good\n",
      "245 mama mia, not good\n",
      "302 mama mia, not good\n",
      "309 mama mia, not good\n",
      "313 mama mia, not good\n",
      "316 mama mia, not good\n",
      "332 mama mia, not good\n",
      "336 mama mia, not good\n",
      "342 mama mia, not good\n",
      "349 mama mia, not good\n",
      "367 mama mia, not good\n",
      "383 mama mia, not good\n",
      "385 mama mia, not good\n",
      "421 mama mia, not good\n",
      "426 mama mia, not good\n",
      "442 mama mia, not good\n",
      "474 mama mia, not good\n",
      "479 mama mia, not good\n",
      "480 mama mia, not good\n",
      "511 mama mia, not good\n",
      "544 mama mia, not good\n",
      "551 mama mia, not good\n",
      "555 mama mia, not good\n",
      "599 mama mia, not good\n",
      "621 mama mia, not good\n",
      "627 mama mia, not good\n",
      "634 mama mia, not good\n",
      "638 mama mia, not good\n",
      "651 mama mia, not good\n",
      "653 mama mia, not good\n",
      "655 mama mia, not good\n",
      "688 mama mia, not good\n",
      "694 mama mia, not good\n",
      "700 mama mia, not good\n",
      "708 mama mia, not good\n",
      "739 mama mia, not good\n",
      "752 mama mia, not good\n",
      "757 mama mia, not good\n",
      "763 mama mia, not good\n",
      "803 mama mia, not good\n",
      "854 mama mia, not good\n",
      "863 mama mia, not good\n",
      "871 mama mia, not good\n",
      "874 mama mia, not good\n",
      "877 mama mia, not good\n",
      "880 mama mia, not good\n",
      "882 mama mia, not good\n",
      "910 mama mia, not good\n",
      "931 mama mia, not good\n",
      "970 mama mia, not good\n",
      "981 mama mia, not good\n",
      "1016 mama mia, not good\n",
      "1031 mama mia, not good\n",
      "1052 mama mia, not good\n",
      "1055 mama mia, not good\n",
      "1071 mama mia, not good\n",
      "1072 mama mia, not good\n",
      "1091 mama mia, not good\n",
      "1093 mama mia, not good\n",
      "1122 mama mia, not good\n",
      "1136 mama mia, not good\n",
      "1156 mama mia, not good\n",
      "1159 mama mia, not good\n",
      "1163 mama mia, not good\n",
      "1176 mama mia, not good\n",
      "1194 mama mia, not good\n",
      "1208 mama mia, not good\n",
      "1222 mama mia, not good\n",
      "1237 mama mia, not good\n",
      "1247 mama mia, not good\n",
      "1263 mama mia, not good\n",
      "1293 mama mia, not good\n",
      "1337 mama mia, not good\n",
      "1346 mama mia, not good\n",
      "1362 mama mia, not good\n",
      "1365 mama mia, not good\n",
      "1367 mama mia, not good\n",
      "1373 mama mia, not good\n",
      "1388 mama mia, not good\n",
      "1400 mama mia, not good\n",
      "1424 mama mia, not good\n",
      "1427 mama mia, not good\n",
      "1433 mama mia, not good\n",
      "1439 mama mia, not good\n",
      "1453 mama mia, not good\n",
      "1468 mama mia, not good\n",
      "1510 mama mia, not good\n",
      "1521 mama mia, not good\n",
      "1530 mama mia, not good\n",
      "1533 mama mia, not good\n",
      "1550 mama mia, not good\n",
      "1553 mama mia, not good\n",
      "1558 mama mia, not good\n",
      "1578 mama mia, not good\n",
      "1582 mama mia, not good\n",
      "1583 mama mia, not good\n",
      "1596 mama mia, not good\n",
      "1600 mama mia, not good\n",
      "1638 mama mia, not good\n",
      "1661 mama mia, not good\n",
      "1671 mama mia, not good\n",
      "1722 mama mia, not good\n",
      "1762 mama mia, not good\n",
      "1775 mama mia, not good\n",
      "1804 mama mia, not good\n",
      "1845 mama mia, not good\n",
      "1857 mama mia, not good\n",
      "1863 mama mia, not good\n",
      "1895 mama mia, not good\n",
      "1898 mama mia, not good\n",
      "1909 mama mia, not good\n",
      "1911 mama mia, not good\n",
      "1918 mama mia, not good\n",
      "1932 mama mia, not good\n",
      "1933 mama mia, not good\n",
      "1940 mama mia, not good\n",
      "1962 mama mia, not good\n",
      "1983 mama mia, not good\n",
      "1993 mama mia, not good\n",
      "2001 mama mia, not good\n",
      "2018 mama mia, not good\n",
      "2021 mama mia, not good\n",
      "2023 mama mia, not good\n",
      "2035 mama mia, not good\n",
      "2045 mama mia, not good\n",
      "2066 mama mia, not good\n",
      "2073 mama mia, not good\n",
      "2106 mama mia, not good\n",
      "2111 mama mia, not good\n",
      "2112 mama mia, not good\n",
      "2119 mama mia, not good\n",
      "2134 mama mia, not good\n",
      "2136 mama mia, not good\n",
      "2149 mama mia, not good\n",
      "2197 mama mia, not good\n",
      "2202 mama mia, not good\n",
      "2219 mama mia, not good\n",
      "2223 mama mia, not good\n",
      "2232 mama mia, not good\n",
      "2255 mama mia, not good\n",
      "2257 mama mia, not good\n",
      "2298 mama mia, not good\n",
      "2299 mama mia, not good\n",
      "2316 mama mia, not good\n",
      "2318 mama mia, not good\n",
      "2321 mama mia, not good\n",
      "2325 mama mia, not good\n",
      "2355 mama mia, not good\n",
      "2359 mama mia, not good\n",
      "2372 mama mia, not good\n",
      "2397 mama mia, not good\n",
      "2454 mama mia, not good\n",
      "2471 mama mia, not good\n",
      "2483 mama mia, not good\n",
      "2502 mama mia, not good\n",
      "2524 mama mia, not good\n",
      "2550 mama mia, not good\n",
      "2560 mama mia, not good\n",
      "2562 mama mia, not good\n",
      "2569 mama mia, not good\n",
      "2586 mama mia, not good\n",
      "2639 mama mia, not good\n",
      "2641 mama mia, not good\n",
      "2651 mama mia, not good\n",
      "2656 mama mia, not good\n",
      "2662 mama mia, not good\n",
      "2663 mama mia, not good\n",
      "2669 mama mia, not good\n",
      "2677 mama mia, not good\n",
      "2684 mama mia, not good\n",
      "2686 mama mia, not good\n",
      "2711 mama mia, not good\n",
      "2739 mama mia, not good\n",
      "2765 mama mia, not good\n",
      "2786 mama mia, not good\n",
      "2843 mama mia, not good\n",
      "2861 mama mia, not good\n",
      "2872 mama mia, not good\n",
      "2883 mama mia, not good\n",
      "2894 mama mia, not good\n",
      "2897 mama mia, not good\n",
      "2902 mama mia, not good\n",
      "2908 mama mia, not good\n",
      "2951 mama mia, not good\n",
      "2961 mama mia, not good\n",
      "2972 mama mia, not good\n",
      "2995 mama mia, not good\n",
      "3065 mama mia, not good\n",
      "3068 mama mia, not good\n",
      "3073 mama mia, not good\n",
      "3078 mama mia, not good\n",
      "3081 mama mia, not good\n",
      "3169 mama mia, not good\n",
      "3181 mama mia, not good\n",
      "3201 mama mia, not good\n",
      "3206 mama mia, not good\n",
      "3216 mama mia, not good\n",
      "3235 mama mia, not good\n",
      "3255 mama mia, not good\n",
      "3262 mama mia, not good\n",
      "3280 mama mia, not good\n",
      "3286 mama mia, not good\n",
      "3291 mama mia, not good\n",
      "3310 mama mia, not good\n",
      "3345 mama mia, not good\n",
      "3362 mama mia, not good\n",
      "3377 mama mia, not good\n",
      "3386 mama mia, not good\n"
     ]
    }
   ],
   "source": [
    "#nonlinear - X_test\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in tqdm(range(X_test_sub.shape[0])):\n",
    "    df = interval_nonlinear(i,df, X_test_sub.loc[i].dropna().to_numpy(dtype='float32'))\n",
    "X_nl_test = df\n",
    "X_nl_test.to_csv('X_nolinear_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d648c",
   "metadata": {},
   "source": [
    "### peaks and intervalls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7158176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(i,ecg_signal):\n",
    "    signal_clean = nk.ecg_clean(ecg_signal, 300)\n",
    "    extracted_features = []\n",
    "    # Delineate the ECG signal: maybe change dwt to cwt\n",
    "    _, rpeaks = nk.ecg_peaks(signal_clean, sampling_rate=300)\n",
    "    peaks, info = nk.ecg_peaks(signal_clean, sampling_rate=300)\n",
    "    if len(rpeaks['ECG_R_Peaks']) >= 4:    \n",
    "        signal_cwt, waves_cwt = nk.ecg_delineate(ecg_signal, rpeaks, sampling_rate=300, method=\"dwt\")\n",
    "        # Signal peaks\n",
    "        x = np.array(rpeaks['ECG_R_Peaks'])\n",
    "        R = np.mean(signal_clean[x[np.isfinite(x)].astype(int)])    \n",
    "\n",
    "        x = np.array(waves_cwt['ECG_P_Peaks'])\n",
    "        P = np.mean(signal_clean[x[np.isfinite(x)].astype(int)])\n",
    "\n",
    "        x = np.array(waves_cwt['ECG_Q_Peaks'])\n",
    "        Q = np.mean(signal_clean[x[np.isfinite(x)].astype(int)])\n",
    "\n",
    "        x = np.array(waves_cwt['ECG_S_Peaks'])\n",
    "        S = np.mean(signal_clean[x[np.isfinite(x)].astype(int)])\n",
    "\n",
    "        x = np.array(waves_cwt['ECG_T_Peaks'])\n",
    "        T = np.mean(signal_clean[x[np.isfinite(x)].astype(int)])\n",
    "\n",
    "\n",
    "        # Intervals, mask due to nan values\n",
    "        x = np.array(waves_cwt['ECG_P_Offsets']).astype(int) - np.array(waves_cwt['ECG_P_Onsets']).astype(int)\n",
    "        mask = np.logical_and(x > -300, x < 300)\n",
    "        Pint = x[mask].mean()    \n",
    "\n",
    "        x = np.array(waves_cwt['ECG_R_Offsets']).astype(int) - np.array(waves_cwt['ECG_R_Onsets']).astype(int)\n",
    "        mask = np.logical_and(x > -300, x < 300)\n",
    "        Rint = x[mask].mean()   \n",
    "\n",
    "        x = np.array(waves_cwt['ECG_T_Offsets']).astype(int) - np.array(waves_cwt['ECG_T_Onsets']).astype(int)\n",
    "        mask = np.logical_and(x > -300, x < 300)\n",
    "        Tint = x[mask].mean()\n",
    "\n",
    "        # Compare beats\n",
    "        r_peaks = ecg.engzee_segmenter(ecg_signal, 300)['rpeaks']\n",
    "        beats = ecg.extract_heartbeats(ecg_signal, r_peaks, 300)['templates']\n",
    "        var = np.std(beats, axis=0)\n",
    "\n",
    "        extracted_features.append([R,P,Q,S,T,Pint,Rint,Tint,var.mean(),var.min(),var.max()])\n",
    "\n",
    "        # R,P,Q,S and T peaks (mean and std of amplitude)\n",
    "        p_peaks = [x for x in waves_cwt['ECG_P_Peaks'] if np.isnan(x) == False]\n",
    "        q_peaks = [x for x in waves_cwt['ECG_Q_Peaks'] if np.isnan(x) == False]\n",
    "        s_peaks = [x for x in waves_cwt['ECG_S_Peaks'] if np.isnan(x) == False]\n",
    "        t_peaks = [x for x in waves_cwt['ECG_T_Peaks'] if np.isnan(x) == False]\n",
    "    \n",
    "        # R,P,Q,S and T peaks (mean and std of amplitude)\n",
    "        extracted_features[0].append(np.std(signal_clean[p_peaks]))\n",
    "        extracted_features[0].append(np.std(signal_clean[q_peaks]))\n",
    "        extracted_features[0].append(np.std(signal_clean[s_peaks]))\n",
    "        extracted_features[0].append(np.std(signal_clean[t_peaks]))\n",
    "\n",
    "    else:\n",
    "        print(i, \"mama mia, not good\")\n",
    "        a = np.empty((1,15,))\n",
    "        a[:] = np.nan \n",
    "        return [a][0]  \n",
    "    \n",
    "    return extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "713291d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a7578fc1484f24ad11a5fdde2dad91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383 mama mia, not good\n",
      "1870 mama mia, not good\n",
      "2433 mama mia, not good\n",
      "3145 mama mia, not good\n",
      "3826 mama mia, not good\n",
      "4388 mama mia, not good\n"
     ]
    }
   ],
   "source": [
    "# Train Data - Transform training dataset of ecg signal into features\n",
    "X_feat = np.zeros(shape=(X.shape[0],15))\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    X_feat[i] = extract_features(i,X.loc[i].dropna().to_numpy(dtype='float32'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd231427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for training and testing\n",
    "columns = ['R','P','Q','S','T','Pint','Rint','Tint','var.mean','var.min','var.max','pstd','qstd','sstd', \\\n",
    "           'tstd']\n",
    "X_feat = pd.DataFrame(X_feat, columns=columns)\n",
    "X_feat.index.name = 'id'\n",
    "\n",
    "X_feat.to_csv('X_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12a8d653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7863422762e8451bb5d8f9c3ea60c2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055 mama mia, not good\n",
      "2325 mama mia, not good\n",
      "2872 mama mia, not good\n"
     ]
    }
   ],
   "source": [
    "# Test data - Transform training dataset of ecg signal into features\n",
    "X_feat_test = np.zeros(shape=(X_test_sub.shape[0],15))\n",
    "for i in tqdm(range(X_test_sub.shape[0])):\n",
    "    X_feat_test[i] = extract_features(i,X_test_sub.loc[i].dropna().to_numpy(dtype='float32'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23e452cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for training and testing\n",
    "columns = ['R','P','Q','S','T','Pint','Rint','Tint','var.mean','var.min','var.max','pstd','qstd','sstd', \\\n",
    "           'tstd']\n",
    "X_feat_test = pd.DataFrame(X_feat_test, columns=columns)\n",
    "X_feat_test.index.name = 'id'\n",
    "\n",
    "X_feat_test.to_csv('X_features_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7060f42a",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4218fbf7",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0728d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('y_train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7ae33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train \n",
    "X_feat = pd.read_csv('X_features.csv', index_col='id')\n",
    "X_frequ = pd.read_csv('X_frequ.csv')\n",
    "X_time = pd.read_csv('X_time.csv')\n",
    "X_nonlinear = pd.read_csv('X_nonlinear.csv')\n",
    "X_frequ.set_index(X_feat.index, inplace=True)\n",
    "X_time.set_index(X_feat.index, inplace=True)\n",
    "X_nonlinear.set_index(X_feat.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee603ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "X_feat_test = pd.read_csv('X_features_test.csv', index_col='id')\n",
    "X_frequ_test = pd.read_csv('X_frequ_test.csv')\n",
    "X_time_test = pd.read_csv('X_time_test.csv')\n",
    "X_nonlinear_test = pd.read_csv('X_nonlinear_test.csv')\n",
    "X_frequ_test.set_index(X_feat_test.index, inplace=True)\n",
    "X_time_test.set_index(X_feat_test.index, inplace=True)\n",
    "X_nonlinear_test.set_index(X_feat_test.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dbeb742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concate\n",
    "df_train = pd.concat([X_feat, X_frequ,X_time,X_nonlinear], axis=1)\n",
    "df_test = pd.concat([X_feat_test, X_frequ_test,X_time_test,X_nonlinear_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5088a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Inf by Nan\n",
    "df_train = df_train.replace([np.inf, -np.inf], np.nan)\n",
    "df_test = df_test.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3223e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete rows with nan\n",
    "df_train=df_train.dropna(axis=1,how='all')\n",
    "df_test=df_test.dropna(axis=1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "122efab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imp = imputer.fit_transform(df_train)\n",
    "X_train_imp = pd.DataFrame(X_train_imp, columns=df_train.columns)\n",
    "X_test_imp = imputer.fit_transform(df_test)\n",
    "X_test_imp = pd.DataFrame(X_test_imp, columns=df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2cb8190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_imp)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=df_train.columns)\n",
    "\n",
    "X_test_scaled = scaler.fit_transform(X_test_imp)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1534c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "selector = SelectKBest(mutual_info_classif, k=70)\n",
    "X_train_scaled = selector.fit_transform(X_train_scaled, np.array(y).ravel()) #70 -> 0.78\n",
    "#X_test_scaled = SelectKBest(mutual_info_classif, k=80).fit_transform(X_test_scaled, np.array(y).ravel()) #70 -> 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6986828f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3411, 70)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sSelect Features in test data\n",
    "cols = selector.get_support(indices=True)\n",
    "X_test_scaled = X_test_scaled.iloc[:,cols]\n",
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80acdce0",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "75d17bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled, y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "af2ac58a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442a8d58342a478a8f0aa0f91f14ce0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of RandomForest: 0.7958984375\n"
     ]
    }
   ],
   "source": [
    "# Classifiers\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "classifiers = {}\n",
    "bagg_class = {}\n",
    "classifiers['RandomForest'] = RandomForestClassifier(criterion='log_loss', class_weight='balanced')\n",
    "#classifiers['DecisionTree'] = DecisionTreeClassifier(criterion='log_loss', class_weight='balanced')\n",
    "#classifiers['SVC'] = SVC(C=5,class_weight='balanced', kernel='rbf')\n",
    "\n",
    "for key, value in tqdm(classifiers.items()):\n",
    "    bagg_class[key] = BaggingClassifier(base_estimator=value, n_estimators=10).fit(X_train, np.array(y_train).ravel())\n",
    "    y_pred = bagg_class[key].predict(X_test)\n",
    "    F1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1 score of {}: {}\".format(key, F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "48167ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedri\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py:451: RuntimeWarning: overflow encountered in exp\n",
      "  - np.log1p(np.exp(-(self.y_train_ * 2 - 1) * f)).sum()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "gpc = GaussianProcessClassifier(kernel=kernel, random_state=0, warm_start=True).fit(X_train, np.array(y_train).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2964155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of gpc: 0.7080078125\n"
     ]
    }
   ],
   "source": [
    "y_pred = gpc.predict(X_test)\n",
    "F1 = f1_score(y_test, y_pred, average='micro')\n",
    "print(\"F1 score of {}: {}\".format('gpc', F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67be7e36",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bff20bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5967bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    " keras.layers.Flatten(input_shape=(99,)),\n",
    " keras.layers.Dense(200, activation=\"relu\"),\n",
    " keras.layers.Dropout(0.5),\n",
    " keras.layers.Dense(300, activation=\"relu\"),\n",
    " keras.layers.Dropout(0.5),\n",
    " keras.layers.Dense(20, activation=\"relu\"),\n",
    " keras.layers.Dense(4, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "05a14756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 99)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 200)               20000     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 300)               60300     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 20)                6020      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 86,404\n",
      "Trainable params: 86,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4b358f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    " optimizer=\"adam\",\n",
    " metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3ac205d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='accuracy', \n",
    "    verbose=1,\n",
    "    patience=20,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2bff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2047/2047 [==============================] - 7s 4ms/step - loss: 0.8123 - accuracy: 0.6665 - val_loss: 0.6839 - val_accuracy: 0.7061\n",
      "Epoch 2/500\n",
      "2047/2047 [==============================] - 8s 4ms/step - loss: 0.6821 - accuracy: 0.7242 - val_loss: 0.6364 - val_accuracy: 0.7412\n",
      "Epoch 3/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.6554 - accuracy: 0.7315 - val_loss: 0.6377 - val_accuracy: 0.7510\n",
      "Epoch 4/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.6405 - accuracy: 0.7501 - val_loss: 0.7063 - val_accuracy: 0.7236\n",
      "Epoch 5/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.6303 - accuracy: 0.7452 - val_loss: 0.6055 - val_accuracy: 0.7461\n",
      "Epoch 6/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.6038 - accuracy: 0.7567 - val_loss: 0.6466 - val_accuracy: 0.7285\n",
      "Epoch 7/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.6028 - accuracy: 0.7520 - val_loss: 0.6018 - val_accuracy: 0.7666\n",
      "Epoch 8/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.5971 - accuracy: 0.7562 - val_loss: 0.6003 - val_accuracy: 0.7725\n",
      "Epoch 9/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5874 - accuracy: 0.7615 - val_loss: 0.5952 - val_accuracy: 0.7490\n",
      "Epoch 10/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5707 - accuracy: 0.7694 - val_loss: 0.6115 - val_accuracy: 0.7393\n",
      "Epoch 11/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5625 - accuracy: 0.7699 - val_loss: 0.6370 - val_accuracy: 0.7432\n",
      "Epoch 12/500\n",
      "2047/2047 [==============================] - 12s 6ms/step - loss: 0.5657 - accuracy: 0.7703 - val_loss: 0.6090 - val_accuracy: 0.7529\n",
      "Epoch 13/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5686 - accuracy: 0.7689 - val_loss: 0.6142 - val_accuracy: 0.7734\n",
      "Epoch 14/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5553 - accuracy: 0.7730 - val_loss: 0.5932 - val_accuracy: 0.7686\n",
      "Epoch 15/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5420 - accuracy: 0.7838 - val_loss: 0.6112 - val_accuracy: 0.7490\n",
      "Epoch 16/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5540 - accuracy: 0.7789 - val_loss: 0.6096 - val_accuracy: 0.7607\n",
      "Epoch 17/500\n",
      "2047/2047 [==============================] - 13s 6ms/step - loss: 0.5470 - accuracy: 0.7821 - val_loss: 0.6105 - val_accuracy: 0.7666\n",
      "Epoch 18/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5333 - accuracy: 0.7926 - val_loss: 0.6191 - val_accuracy: 0.7676\n",
      "Epoch 19/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.5442 - accuracy: 0.7774 - val_loss: 0.5913 - val_accuracy: 0.7588\n",
      "Epoch 20/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5279 - accuracy: 0.7887 - val_loss: 0.6026 - val_accuracy: 0.7705\n",
      "Epoch 21/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5204 - accuracy: 0.7904 - val_loss: 0.6211 - val_accuracy: 0.7549\n",
      "Epoch 22/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5180 - accuracy: 0.7906 - val_loss: 0.5996 - val_accuracy: 0.7676\n",
      "Epoch 23/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5317 - accuracy: 0.7914 - val_loss: 0.6124 - val_accuracy: 0.7803\n",
      "Epoch 24/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5238 - accuracy: 0.7945 - val_loss: 0.5913 - val_accuracy: 0.7803\n",
      "Epoch 25/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.5138 - accuracy: 0.7962 - val_loss: 0.5926 - val_accuracy: 0.7646\n",
      "Epoch 26/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5062 - accuracy: 0.8004 - val_loss: 0.6076 - val_accuracy: 0.7686\n",
      "Epoch 27/500\n",
      "2047/2047 [==============================] - 11s 5ms/step - loss: 0.5082 - accuracy: 0.7965 - val_loss: 0.6118 - val_accuracy: 0.7695\n",
      "Epoch 28/500\n",
      "2047/2047 [==============================] - 8s 4ms/step - loss: 0.5085 - accuracy: 0.7982 - val_loss: 0.6063 - val_accuracy: 0.7461\n",
      "Epoch 29/500\n",
      "2047/2047 [==============================] - 8s 4ms/step - loss: 0.5079 - accuracy: 0.7962 - val_loss: 0.6073 - val_accuracy: 0.7393\n",
      "Epoch 30/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.5146 - accuracy: 0.7918 - val_loss: 0.6021 - val_accuracy: 0.7568\n",
      "Epoch 31/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.4979 - accuracy: 0.8019 - val_loss: 0.5915 - val_accuracy: 0.7695\n",
      "Epoch 32/500\n",
      "2047/2047 [==============================] - 13s 6ms/step - loss: 0.5020 - accuracy: 0.7965 - val_loss: 0.6021 - val_accuracy: 0.7734\n",
      "Epoch 33/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.4993 - accuracy: 0.7977 - val_loss: 0.5926 - val_accuracy: 0.7646\n",
      "Epoch 34/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.4775 - accuracy: 0.8077 - val_loss: 0.6008 - val_accuracy: 0.7666\n",
      "Epoch 35/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.4821 - accuracy: 0.8102 - val_loss: 0.6330 - val_accuracy: 0.7617\n",
      "Epoch 36/500\n",
      "2047/2047 [==============================] - 7s 4ms/step - loss: 0.4787 - accuracy: 0.8119 - val_loss: 0.6418 - val_accuracy: 0.7490\n",
      "Epoch 37/500\n",
      "2047/2047 [==============================] - 13s 6ms/step - loss: 0.4724 - accuracy: 0.8160 - val_loss: 0.6268 - val_accuracy: 0.7627\n",
      "Epoch 38/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.4682 - accuracy: 0.8180 - val_loss: 0.6237 - val_accuracy: 0.7607\n",
      "Epoch 39/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.4762 - accuracy: 0.8097 - val_loss: 0.6108 - val_accuracy: 0.7568\n",
      "Epoch 40/500\n",
      "2047/2047 [==============================] - 7s 4ms/step - loss: 0.4761 - accuracy: 0.8148 - val_loss: 0.6389 - val_accuracy: 0.7598\n",
      "Epoch 41/500\n",
      "2047/2047 [==============================] - 10s 5ms/step - loss: 0.4757 - accuracy: 0.8126 - val_loss: 0.6092 - val_accuracy: 0.7686\n",
      "Epoch 42/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.4725 - accuracy: 0.8092 - val_loss: 0.6416 - val_accuracy: 0.7529\n",
      "Epoch 43/500\n",
      "2047/2047 [==============================] - 12s 6ms/step - loss: 0.4606 - accuracy: 0.8202 - val_loss: 0.6440 - val_accuracy: 0.7529\n",
      "Epoch 44/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.4560 - accuracy: 0.8160 - val_loss: 0.6173 - val_accuracy: 0.7549\n",
      "Epoch 45/500\n",
      "2047/2047 [==============================] - 7s 4ms/step - loss: 0.4631 - accuracy: 0.8058 - val_loss: 0.6489 - val_accuracy: 0.7549\n",
      "Epoch 46/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.4628 - accuracy: 0.8192 - val_loss: 0.6316 - val_accuracy: 0.7666\n",
      "Epoch 47/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.4450 - accuracy: 0.8268 - val_loss: 0.6422 - val_accuracy: 0.7773\n",
      "Epoch 48/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.4429 - accuracy: 0.8270 - val_loss: 0.6595 - val_accuracy: 0.7666\n",
      "Epoch 49/500\n",
      "2047/2047 [==============================] - 13s 6ms/step - loss: 0.4527 - accuracy: 0.8197 - val_loss: 0.6213 - val_accuracy: 0.7725\n",
      "Epoch 50/500\n",
      "2047/2047 [==============================] - 15s 7ms/step - loss: 0.4410 - accuracy: 0.8278 - val_loss: 0.6240 - val_accuracy: 0.7529\n",
      "Epoch 51/500\n",
      "2047/2047 [==============================] - 7s 4ms/step - loss: 0.4433 - accuracy: 0.8243 - val_loss: 0.6481 - val_accuracy: 0.7725\n",
      "Epoch 52/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.4588 - accuracy: 0.8322 - val_loss: 0.6245 - val_accuracy: 0.7549\n",
      "Epoch 53/500\n",
      "2047/2047 [==============================] - 13s 6ms/step - loss: 0.4525 - accuracy: 0.8234 - val_loss: 0.6108 - val_accuracy: 0.7627\n",
      "Epoch 54/500\n",
      "2047/2047 [==============================] - 12s 6ms/step - loss: 0.4397 - accuracy: 0.8251 - val_loss: 0.6350 - val_accuracy: 0.7578\n",
      "Epoch 55/500\n",
      "2047/2047 [==============================] - 13s 6ms/step - loss: 0.4381 - accuracy: 0.8322 - val_loss: 0.6350 - val_accuracy: 0.7666\n",
      "Epoch 56/500\n",
      "2047/2047 [==============================] - 13s 6ms/step - loss: 0.4446 - accuracy: 0.8292 - val_loss: 0.6456 - val_accuracy: 0.7510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "2047/2047 [==============================] - 12s 6ms/step - loss: 0.4572 - accuracy: 0.8297 - val_loss: 0.6610 - val_accuracy: 0.7568\n",
      "Epoch 58/500\n",
      "2047/2047 [==============================] - 14s 7ms/step - loss: 0.4436 - accuracy: 0.8231 - val_loss: 0.6247 - val_accuracy: 0.7617\n",
      "Epoch 59/500\n",
      "2047/2047 [==============================] - 8s 4ms/step - loss: 0.4232 - accuracy: 0.8380 - val_loss: 0.6329 - val_accuracy: 0.7578\n",
      "Epoch 60/500\n",
      "2047/2047 [==============================] - 7s 4ms/step - loss: 0.4360 - accuracy: 0.8317 - val_loss: 0.6281 - val_accuracy: 0.7627\n",
      "Epoch 61/500\n",
      "2047/2047 [==============================] - 5s 2ms/step - loss: 0.4173 - accuracy: 0.8334 - val_loss: 0.6836 - val_accuracy: 0.7646\n",
      "Epoch 62/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4308 - accuracy: 0.8351 - val_loss: 0.6512 - val_accuracy: 0.7598\n",
      "Epoch 63/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4277 - accuracy: 0.8361 - val_loss: 0.6750 - val_accuracy: 0.7588\n",
      "Epoch 64/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4423 - accuracy: 0.8312 - val_loss: 0.7005 - val_accuracy: 0.7627\n",
      "Epoch 65/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4233 - accuracy: 0.8390 - val_loss: 0.7006 - val_accuracy: 0.7598\n",
      "Epoch 66/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4176 - accuracy: 0.8378 - val_loss: 0.6950 - val_accuracy: 0.7578\n",
      "Epoch 67/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4206 - accuracy: 0.8390 - val_loss: 0.6436 - val_accuracy: 0.7666\n",
      "Epoch 68/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4309 - accuracy: 0.8417 - val_loss: 0.6743 - val_accuracy: 0.7695\n",
      "Epoch 69/500\n",
      "2047/2047 [==============================] - 5s 2ms/step - loss: 0.4272 - accuracy: 0.8373 - val_loss: 0.6561 - val_accuracy: 0.7744\n",
      "Epoch 70/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4194 - accuracy: 0.8405 - val_loss: 0.6373 - val_accuracy: 0.7617\n",
      "Epoch 71/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4098 - accuracy: 0.8468 - val_loss: 0.6589 - val_accuracy: 0.7617\n",
      "Epoch 72/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4211 - accuracy: 0.8356 - val_loss: 0.6820 - val_accuracy: 0.7627\n",
      "Epoch 73/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4263 - accuracy: 0.8424 - val_loss: 0.6703 - val_accuracy: 0.7666\n",
      "Epoch 74/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4290 - accuracy: 0.8385 - val_loss: 0.6768 - val_accuracy: 0.7568\n",
      "Epoch 75/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4119 - accuracy: 0.8429 - val_loss: 0.6920 - val_accuracy: 0.7490\n",
      "Epoch 76/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4311 - accuracy: 0.8405 - val_loss: 0.6648 - val_accuracy: 0.7656\n",
      "Epoch 77/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4069 - accuracy: 0.8405 - val_loss: 0.6659 - val_accuracy: 0.7461\n",
      "Epoch 78/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4181 - accuracy: 0.8461 - val_loss: 0.6788 - val_accuracy: 0.7510\n",
      "Epoch 79/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4092 - accuracy: 0.8395 - val_loss: 0.6697 - val_accuracy: 0.7666\n",
      "Epoch 80/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4325 - accuracy: 0.8326 - val_loss: 0.6565 - val_accuracy: 0.7627\n",
      "Epoch 81/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3891 - accuracy: 0.8512 - val_loss: 0.6679 - val_accuracy: 0.7539\n",
      "Epoch 82/500\n",
      "2047/2047 [==============================] - 9s 5ms/step - loss: 0.4075 - accuracy: 0.8407 - val_loss: 0.6736 - val_accuracy: 0.7451\n",
      "Epoch 83/500\n",
      "2047/2047 [==============================] - 5s 2ms/step - loss: 0.4031 - accuracy: 0.8475 - val_loss: 0.6688 - val_accuracy: 0.7549\n",
      "Epoch 84/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4127 - accuracy: 0.8475 - val_loss: 0.6596 - val_accuracy: 0.7529\n",
      "Epoch 85/500\n",
      "2047/2047 [==============================] - 6s 3ms/step - loss: 0.3971 - accuracy: 0.8461 - val_loss: 0.6941 - val_accuracy: 0.7617\n",
      "Epoch 86/500\n",
      "2047/2047 [==============================] - 7s 4ms/step - loss: 0.4125 - accuracy: 0.8522 - val_loss: 0.7162 - val_accuracy: 0.7559s: 0.4077 - accu\n",
      "Epoch 87/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4027 - accuracy: 0.8485 - val_loss: 0.6919 - val_accuracy: 0.7676\n",
      "Epoch 88/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3961 - accuracy: 0.8475 - val_loss: 0.6996 - val_accuracy: 0.7627\n",
      "Epoch 89/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3937 - accuracy: 0.8505 - val_loss: 0.6414 - val_accuracy: 0.7559\n",
      "Epoch 90/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3960 - accuracy: 0.8495 - val_loss: 0.6881 - val_accuracy: 0.7588\n",
      "Epoch 91/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4065 - accuracy: 0.8488 - val_loss: 0.6680 - val_accuracy: 0.7510\n",
      "Epoch 92/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3938 - accuracy: 0.8539 - val_loss: 0.7005 - val_accuracy: 0.7490\n",
      "Epoch 93/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4039 - accuracy: 0.8534 - val_loss: 0.6942 - val_accuracy: 0.7461\n",
      "Epoch 94/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3945 - accuracy: 0.8534 - val_loss: 0.7079 - val_accuracy: 0.7529\n",
      "Epoch 95/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.4030 - accuracy: 0.8483 - val_loss: 0.7243 - val_accuracy: 0.7314\n",
      "Epoch 96/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3780 - accuracy: 0.8539 - val_loss: 0.7235 - val_accuracy: 0.7607\n",
      "Epoch 97/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3903 - accuracy: 0.8515 - val_loss: 0.7511 - val_accuracy: 0.7588\n",
      "Epoch 98/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3855 - accuracy: 0.8549 - val_loss: 0.7626 - val_accuracy: 0.7656\n",
      "Epoch 99/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3973 - accuracy: 0.8512 - val_loss: 0.7633 - val_accuracy: 0.7656\n",
      "Epoch 100/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3840 - accuracy: 0.8522 - val_loss: 0.7766 - val_accuracy: 0.7539\n",
      "Epoch 101/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3943 - accuracy: 0.8478 - val_loss: 0.6712 - val_accuracy: 0.7568\n",
      "Epoch 102/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3969 - accuracy: 0.8519 - val_loss: 0.7565 - val_accuracy: 0.7529\n",
      "Epoch 103/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3843 - accuracy: 0.8595 - val_loss: 0.6988 - val_accuracy: 0.7578\n",
      "Epoch 104/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3952 - accuracy: 0.8527 - val_loss: 0.7261 - val_accuracy: 0.7607\n",
      "Epoch 105/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3810 - accuracy: 0.8612 - val_loss: 0.7232 - val_accuracy: 0.7539\n",
      "Epoch 106/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3728 - accuracy: 0.8598 - val_loss: 0.7928 - val_accuracy: 0.7471\n",
      "Epoch 107/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3929 - accuracy: 0.8524 - val_loss: 0.7056 - val_accuracy: 0.7520\n",
      "Epoch 108/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3575 - accuracy: 0.8607 - val_loss: 0.7684 - val_accuracy: 0.7646\n",
      "Epoch 109/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3771 - accuracy: 0.8659 - val_loss: 0.7309 - val_accuracy: 0.7705\n",
      "Epoch 110/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3752 - accuracy: 0.8581 - val_loss: 0.7008 - val_accuracy: 0.7549\n",
      "Epoch 111/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3677 - accuracy: 0.8581 - val_loss: 0.7513 - val_accuracy: 0.7656\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2047/2047 [==============================] - 3s 2ms/step - loss: 0.3798 - accuracy: 0.8585 - val_loss: 0.7477 - val_accuracy: 0.7715\n",
      "Epoch 113/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3626 - accuracy: 0.8600 - val_loss: 0.7472 - val_accuracy: 0.7617 - ETA: 0s - loss: 0.3572 - accuracy\n",
      "Epoch 114/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3719 - accuracy: 0.8605 - val_loss: 0.6825 - val_accuracy: 0.7568\n",
      "Epoch 115/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3753 - accuracy: 0.8605 - val_loss: 0.7453 - val_accuracy: 0.7607\n",
      "Epoch 116/500\n",
      "2047/2047 [==============================] - 3s 2ms/step - loss: 0.3718 - accuracy: 0.8571 - val_loss: 0.7551 - val_accuracy: 0.7529\n",
      "Epoch 117/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3929 - accuracy: 0.8610 - val_loss: 0.7139 - val_accuracy: 0.7539\n",
      "Epoch 118/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3621 - accuracy: 0.8698 - val_loss: 0.7107 - val_accuracy: 0.7637\n",
      "Epoch 119/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3626 - accuracy: 0.8602 - val_loss: 0.6968 - val_accuracy: 0.7578.347\n",
      "Epoch 120/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3664 - accuracy: 0.8637 - val_loss: 0.7304 - val_accuracy: 0.7637\n",
      "Epoch 121/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3531 - accuracy: 0.8671 - val_loss: 0.7413 - val_accuracy: 0.7393\n",
      "Epoch 122/500\n",
      "2047/2047 [==============================] - 3s 2ms/step - loss: 0.3362 - accuracy: 0.8717 - val_loss: 0.8132 - val_accuracy: 0.7588\n",
      "Epoch 123/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3792 - accuracy: 0.8642 - val_loss: 0.7168 - val_accuracy: 0.7627\n",
      "Epoch 124/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3529 - accuracy: 0.8661 - val_loss: 0.7892 - val_accuracy: 0.7607\n",
      "Epoch 125/500\n",
      "2047/2047 [==============================] - 4s 2ms/step - loss: 0.3598 - accuracy: 0.8620 - val_loss: 0.7597 - val_accuracy: 0.7578\n",
      "Epoch 126/500\n",
      "2020/2047 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8626"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=500, validation_data=(X_test, y_test),batch_size=2,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e2fbd2",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3912d0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(base_estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                        criterion=&#x27;log_loss&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(base_estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                        criterion=&#x27;log_loss&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;log_loss&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;log_loss&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(base_estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                                        criterion='log_loss'))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on whole train set \n",
    "bagg_class['RandomForest'].fit(X_train_scaled, np.array(y).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6bb3012b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedri\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prediction on submission test set\n",
    "submission = bagg_class['RandomForest'].predict(X_test_scaled)\n",
    "df_submission = pd.DataFrame({'id': df_test.index, 'y': submission})\n",
    "# Save into csv file\n",
    "df_submission.to_csv('RandomForest_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fec830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
